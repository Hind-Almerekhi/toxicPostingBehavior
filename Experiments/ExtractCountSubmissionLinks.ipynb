{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4abb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "import glob\n",
    "import mimetypes\n",
    "from collections import Counter\n",
    "from urlextract import URLExtract\n",
    "root_dir = os.path.abspath(os.curdir)\n",
    "dir_subs = os.path.dirname(root_dir)+\"/ExtractedSubmissions/\"\n",
    "#Create directory to save experiment results\n",
    "sublinks_dir = os.path.dirname(root_dir)+\"/SubmissionLinks/\"\n",
    "os.makedirs(sublinks_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32861b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "2007\n"
     ]
    }
   ],
   "source": [
    "#Extract links\n",
    "fields = [\"ID\",\"Author\",\"LinkID\",\"Subreddit\",\"Text\",\"Time\",\"Links\"]\n",
    "for year in range(2006,2008):\n",
    "    print(year)\n",
    "    df = pd.read_csv(dir_subs+str(year)+'.csv',header=None,names=fields)\n",
    "    df = df[[\"ID\",\"Author\",\"Subreddit\",\"Time\",\"Links\"]]\n",
    "    output = sublinks_dir+str(year)+'.csv'\n",
    "    df.to_csv(output,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 1, count images\n",
    "counter = 0\n",
    "imCounter = 0\n",
    "for year in range(2006,2008):\n",
    "    print(year)\n",
    "    file = sublinks_dir+str(year)+'.csv'\n",
    "    with open(file,'r', encoding='utf-8') as fin:\n",
    "        first = fin.readline()\n",
    "        for line in fin:\n",
    "            counter+=1\n",
    "            data = line.strip().split(',')\n",
    "            links = ','.join(data[1:])\n",
    "            medtype = mimetypes.MimeTypes().guess_type(links)[0]\n",
    "            if medtype != None and 'image/' in medtype:\n",
    "                #print(links)\n",
    "                imCounter+=1\n",
    "    print(\"Total links:\",counter)\n",
    "    print(\"Total images:\",imCounter)\n",
    "    counter=0\n",
    "    imCounter=0\n",
    "\n",
    "#Test2 count reddit links vs other links (inbound outbound)\n",
    "counter = 0\n",
    "inCounter = 0\n",
    "outCounter=0\n",
    "skip = 0\n",
    "usable=0\n",
    "for year in range(2006,2008):\n",
    "    print(year)\n",
    "    file = sublinks_dir+str(year)+'.csv'\n",
    "    with open(file,'r') as fin:\n",
    "        first = fin.readline()\n",
    "        for line in fin:\n",
    "            counter+=1\n",
    "            data = line.strip().split(',')\n",
    "            links = ','.join(data[1:])\n",
    "            #print(links)\n",
    "            if 'www.reddit.com/r/' in links:\n",
    "                skip+=1\n",
    "                #print(links)\n",
    "            elif 'redd.it' in links or 'www.reddit.com/user/' in links:\n",
    "                usable+=1\n",
    "                inCounter+=1\n",
    "            elif 'reddit.com/s/' in links:\n",
    "                usable+=1\n",
    "                outCounter+=1\n",
    "            else:\n",
    "                usable+=1\n",
    "                outCounter+=1\n",
    "    print(\"Total available links:\",counter)\n",
    "    un = (skip/counter)*100\n",
    "    print(\"Total posts with no links:\",skip,'('+str(format(un,'.2f'))+'%'+')')\n",
    "    pre = (usable/counter)*100\n",
    "    print(\"Total actually usable links:\",usable,'('+str(format(pre,'.2f'))+'%'+')')\n",
    "    pre1 = (inCounter/usable)*100\n",
    "    print(\"Total internal links:\",inCounter,'('+str(format(pre1,'.2f'))+'%'+')')\n",
    "    pre2 = (outCounter/usable)*100\n",
    "    print(\"Total external links:\",outCounter,'('+str(format(pre2,'.2f'))+'%'+')')\n",
    "    counter=0\n",
    "    inCounter=0\n",
    "    outCounter=0\n",
    "    skip=0\n",
    "    usable=0\n",
    "\n",
    "# #Test3 find data types from the raw links in submissions\n",
    "counter = 0\n",
    "knownTypes = 0\n",
    "allMedia=[]\n",
    "for year in range(2006,2008):\n",
    "    print(year)\n",
    "    media=[]\n",
    "    file =sublinks_dir+str(year)+'.csv'\n",
    "    with open(file,'r') as fin:\n",
    "        first = fin.readline()\n",
    "        for line in fin:\n",
    "            counter+=1\n",
    "            data = line.strip().split(',')\n",
    "            links = ','.join(data[1:])\n",
    "            #print(links)\n",
    "            medtype = mimetypes.MimeTypes().guess_type(links)[0]\n",
    "            if medtype != None:\n",
    "                media.append(medtype)\n",
    "                allMedia.append(medtype)\n",
    "                knownTypes+=1\n",
    "    print(\"Total links:\",counter)\n",
    "    print(\"Total known media types:\",knownTypes)\n",
    "    print(dict(Counter(media)))\n",
    "    counter=0\n",
    "    knownTypes=0\n",
    "print(\"Total collection:\")\n",
    "print(Counter(allMedia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2c248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
