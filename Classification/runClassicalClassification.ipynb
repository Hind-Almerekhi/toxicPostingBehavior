{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd94a23",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ff6557",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pickle \n",
    "import mglearn\n",
    "import time\n",
    "import os\n",
    "root_dir = os.path.abspath(os.curdir)\n",
    "feat_dir = os.path.dirname(root_dir)+\"/Features/\"\n",
    "import nltk\n",
    "from nltk import Text\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.tokenize import sent_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from imblearn.combine import SMOTETomek \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "SEED=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642d5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "LRparams = dict()\n",
    "#1e-5, 1e-4, 1e-3, 1e-2,\n",
    "LRparams['C'] = [1, 10, 100]\n",
    "LRparams['dual'] = [True,False]\n",
    "LRparams['fit_intercept'] = [True,False]\n",
    "LRparams['penalty'] = ['none', 'l1', 'l2']\n",
    "LRparams['solver'] = ['newton-cg', 'lbfgs', 'liblinear','sag', 'saga']\n",
    "LRparams['max_iter'] = [10000]\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "RFparams = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "DTparams = {\n",
    "     'criterion' : ['gini', 'entropy'],\n",
    "     'max_depth' : range(2, 32, 1),\n",
    "     'min_samples_leaf' : range(1, 10, 1),\n",
    "     'min_samples_split' : range(2, 10, 1),\n",
    "     'splitter' : ['best', 'random']}\n",
    "\n",
    "MNparams = dict()\n",
    "MNparams['alpha'] = np.linspace(0.5, 1.5, 6)\n",
    "MNparams['fit_prior'] = [True, False]\n",
    "\n",
    "XGBparams = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2),\n",
    "    'colsample_bytree': [1.0,0.9,0.8],\n",
    "#     'max_depth': range(2, 10, 1),\n",
    "    'n_estimators': [300],\n",
    "#     'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'learning_rate': [0.3],\n",
    "    'tree_method' : ['gpu_hist'],\n",
    "    'subsample': [1]}\n",
    "\n",
    "classifierInfo = [(\"Logistic Regression\", LogisticRegression(random_state=SEED),LRparams),\\\n",
    "                  (\"Random Forest\", RandomForestClassifier(random_state=SEED),RFparams),\\\n",
    "                  (\"Decision Tree\",DecisionTreeClassifier(random_state=SEED),DTparams),\\\n",
    "                 (\"MultinomialNB\",MultinomialNB(),MNparams),\\\n",
    "                (\"XGBoost\",XGBClassifier(random_state=SEED,objective='multi:softmax',nthread=4,\\\n",
    "                use_label_encoder=False,gpu_id=-1,eval_metric='merror'),XGBparams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e85aa50",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Read targets and get class distributions \n",
    "    with open(feat_dir+'target.pkl','rb') as f: y = pickle.load(f)\n",
    "    y = y.astype(int)\n",
    "    y = y.flatten()\n",
    "    nontox, slightly, highly = np.bincount(y)\n",
    "    total = nontox + slightly + highly\n",
    "    print('Total: {}\\n    Non toxic: {} ({:.2f}% of total)\\n'.format(\n",
    "        total, nontox, 100 * nontox / total))\n",
    "    print('Total: {}\\n    Slightly toxic: {} ({:.2f}% of total)\\n'.format(\n",
    "        total, slightly, 100 * slightly / total))\n",
    "    print('Total: {}\\n    Highly toxic: {} ({:.2f}% of total)\\n'.format(\n",
    "        total, highly, 100 * highly / total))\n",
    "    print('―' * 100)\n",
    "    \n",
    "    featureFiles = {'tf.pkl':'Unigram','tfbig.pkl':'Bigram','tfn.pkl':'Ngram','tfidf.pkl':'TFIDF',\\\n",
    "    'hatefulFeats.pkl':'Hateful','word2vec-features.pkl':'Word2Vec','doc2vec-features.pkl':'Doc2Vec',\\\n",
    "                    'allFeatures.pkl':'All'}\n",
    "\n",
    "\n",
    "    for filename, title in featureFiles.items(): \n",
    "        with open(feat_dir+filename,'rb') as f: train = pickle.load(f)\n",
    "        x = train\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2,stratify=y,random_state=SEED)\n",
    "        print(title+\" features\\n\")\n",
    "        X_data_transformed, Y_data_transformed = performStandardization(X_train,X_test)\n",
    "        train_fs, test_fs = performFeatureSelection(X_data_transformed,Y_data_transformed,y_train)\n",
    "#         X_resampled,y_resampled = performClassImbalanceHandling(train_fs, y_train)\n",
    "        for classifier in classifierInfo:\n",
    "            clfname = classifier[0]\n",
    "            clf_model = classifier[1]\n",
    "            clf_params = classifier[2]\n",
    "            gridResult = runClassification(clfname,clf_model,clf_params,train_fs, y_train)\n",
    "            performPrediction(gridResult,test_fs,y_test)\n",
    "        print('―' * 100)\n",
    "    print(\"\\nDone!\")\n",
    "            \n",
    "def performStandardization(train,test):\n",
    "    #Perform standardization for the training and testing sets (step 1)\n",
    "    scaler = preprocessing.MinMaxScaler().fit(train) #MaxAbsScaler\n",
    "    X_data_transformed = scaler.transform(train)\n",
    "\n",
    "    # #Do the same for testing\n",
    "    Y_data_transformed = scaler.transform(test)\n",
    "    return X_data_transformed, Y_data_transformed\n",
    "\n",
    "def performFeatureSelection(train,test,y):\n",
    "    # Feature Selection Method 1: Random Forest Based feature selection (step 2)\n",
    "    print(\"Shape before feature selection:\",train.shape)\n",
    "    clf = RandomForestClassifier(random_state=SEED)\n",
    "    clf = clf.fit(train,y)\n",
    "    #print(clf.feature_importances_ ) \n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    train_fs = model.transform(train)\n",
    "\n",
    "    test_fs = model.transform(test)\n",
    "    print(\"Shape after feature selection:\",train_fs.shape) \n",
    "    return train_fs, test_fs\n",
    "\n",
    "def performClassImbalanceHandling(train,y):\n",
    "    #Apply sampling on training set only (step 3)\n",
    "    imbalanceHandeler = SMOTETomek(random_state=SEED,n_jobs=-1) #,sampling_strategy=strategy\n",
    "    X_resampled, y_resampled = imbalanceHandeler.fit_resample(train, y)\n",
    "    #Counts\n",
    "    print(\"Number of training instances before sampling:\",train.shape[0])\n",
    "    print(\"Distribution in each class before sampling:\")\n",
    "    print(pd.Series(y).value_counts())\n",
    "    print()\n",
    "    print(\"Number of training instances after sampling:\",X_resampled.shape[0])\n",
    "    print(\"Distribution in each class after sampling:\")\n",
    "    print(pd.Series(y_resampled).value_counts())\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def runClassification(clfname,clf_model,clf_params,X_resampled, y_resampled):\n",
    "    scoring = ['roc_auc_ovr','f1_macro']\n",
    "    rnd_clf = clf_model\n",
    "    print('─' * 100) \n",
    "    print(clfname)\n",
    "    print('_' * 100)\n",
    "#     print('Parameters currently in use:\\n')\n",
    "#     pprint(rnd_clf.get_params())\n",
    "    \n",
    "    #Perform random grid search\n",
    "    rf_random = RandomizedSearchCV(estimator=rnd_clf, param_distributions=clf_params,cv = 3, verbose=2,random_state=SEED,scoring=scoring, \n",
    "                          refit='roc_auc_ovr', n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_resampled[:1000], y_resampled[:1000])\n",
    "    #Get best parameters from random search\n",
    "    best = rf_random.best_params_\n",
    "    # param_grid = {}\n",
    "    keys = []\n",
    "    vals = []\n",
    "    for k, v in best.items():\n",
    "        _k = 'clf_cv__'+k\n",
    "        _v = [v]\n",
    "        keys.append(_k)\n",
    "        vals.append(_v)\n",
    "\n",
    "    param_grid = {key: value for key, value in zip(keys, vals)}\n",
    "    \n",
    "    #Perform classification\n",
    "    class_clf = clf_model #, max_iter=4000\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=SEED)\n",
    "\n",
    "#     steps = [('clf_cv',class_clf)]\n",
    "#     pipe = Pipeline(steps=steps)\n",
    "    pipeline = imbpipeline(steps = [['smotetomek', SMOTETomek(random_state=SEED,n_jobs=-1)],\n",
    "                                ['clf_cv', class_clf]])\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=cv, scoring=scoring, \n",
    "                              refit='roc_auc_ovr', return_train_score=True,verbose=2, n_jobs=-1)#roc_auc_ovr\n",
    "\n",
    "    gridResult = grid.fit(X_resampled , y_resampled)\n",
    "    print(\"Best parameters:\\n\")\n",
    "    pprint(gridResult.best_params_)\n",
    "    #Evaluate\n",
    "    print(\"Training ROC AUC score: {a} ({b})\"\\\n",
    "          .format(a=gridResult.best_score_,b=gridResult.cv_results_['std_test_roc_auc_ovr'].max()))\n",
    "    return gridResult\n",
    "\n",
    "def performPrediction(gridResult,test_fs,y_test):\n",
    "    predicted_y_test = gridResult.predict(test_fs)\n",
    "    proba_y_test = gridResult.predict_proba(test_fs)\n",
    "    print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(y_test, predicted_y_test)))\n",
    "    print(\"\\nClassification report: \\n{}\".format(classification_report(y_test, predicted_y_test)))\n",
    "\n",
    "    print(\"Accuracy: \",accuracy_score(y_test, predicted_y_test))\n",
    "    f1 = f1_score(y_test, predicted_y_test, average='macro')\n",
    "    pre = precision_score(y_test, predicted_y_test, average='macro')\n",
    "    rec = recall_score(y_test, predicted_y_test, average='macro')\n",
    "    acc = accuracy_score(y_test, predicted_y_test)\n",
    "    print('Precision:',pre)\n",
    "    print('Recall:',rec)\n",
    "    print('F1:',f1)\n",
    "    print(\"ROC AUC Score:{}\".format(roc_auc_score(y_test,proba_y_test,multi_class='ovr')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10065\n",
      "    Non toxic: 8210 (81.57% of total)\n",
      "\n",
      "Total: 10065\n",
      "    Slightly toxic: 1189 (11.81% of total)\n",
      "\n",
      "Total: 10065\n",
      "    Highly toxic: 666 (6.62% of total)\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Unigram features\n",
      "\n",
      "Shape before feature selection: (8052, 3000)\n",
      "Shape after feature selection: (8052, 521)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Logistic Regression\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 452, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver saga supports only dual=False, got dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.72839805 0.71513032        nan        nan        nan 0.76857053\n",
      "        nan        nan        nan 0.70407798]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.49920758 0.51232743        nan        nan        nan 0.45246403\n",
      "        nan        nan        nan 0.47208566]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__C': 10,\n",
      " 'clf_cv__dual': False,\n",
      " 'clf_cv__fit_intercept': True,\n",
      " 'clf_cv__max_iter': 10000,\n",
      " 'clf_cv__penalty': 'l2',\n",
      " 'clf_cv__solver': 'lbfgs'}\n",
      "Training ROC AUC score: 0.8549902207563967 (0.011711018628895406)\n",
      "Confusion Matrix: \n",
      "[[1500  119   23]\n",
      " [  61  132   45]\n",
      " [   8   44   81]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1642\n",
      "           1       0.45      0.55      0.50       238\n",
      "           2       0.54      0.61      0.57       133\n",
      "\n",
      "    accuracy                           0.85      2013\n",
      "   macro avg       0.65      0.69      0.67      2013\n",
      "weighted avg       0.87      0.85      0.86      2013\n",
      "\n",
      "Accuracy:  0.8509687034277198\n",
      "Precision: 0.6490349109143796\n",
      "Recall: 0.6923881675242057\n",
      "F1: 0.668022012422593\n",
      "ROC AUC Score:0.87812379186431\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Random Forest\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__bootstrap': False,\n",
      " 'clf_cv__max_depth': 40,\n",
      " 'clf_cv__max_features': 'sqrt',\n",
      " 'clf_cv__min_samples_leaf': 1,\n",
      " 'clf_cv__min_samples_split': 2,\n",
      " 'clf_cv__n_estimators': 200}\n",
      "Training ROC AUC score: 0.880661241881284 (0.009485662414038214)\n",
      "Confusion Matrix: \n",
      "[[1631    9    2]\n",
      " [ 187   39   12]\n",
      " [  76   34   23]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      1642\n",
      "           1       0.48      0.16      0.24       238\n",
      "           2       0.62      0.17      0.27       133\n",
      "\n",
      "    accuracy                           0.84      2013\n",
      "   macro avg       0.65      0.44      0.48      2013\n",
      "weighted avg       0.80      0.84      0.80      2013\n",
      "\n",
      "Accuracy:  0.8410332836562344\n",
      "Precision: 0.6527906070749968\n",
      "Recall: 0.4433662432214376\n",
      "F1: 0.4789498491704374\n",
      "ROC AUC Score:0.8822654169404055\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Decision Tree\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__criterion': 'gini',\n",
      " 'clf_cv__max_depth': 29,\n",
      " 'clf_cv__min_samples_leaf': 9,\n",
      " 'clf_cv__min_samples_split': 7,\n",
      " 'clf_cv__splitter': 'best'}\n",
      "Training ROC AUC score: 0.7592582441292497 (0.01986538078270269)\n",
      "Confusion Matrix: \n",
      "[[1548   71   23]\n",
      " [  83  117   38]\n",
      " [  15   67   51]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1642\n",
      "           1       0.46      0.49      0.47       238\n",
      "           2       0.46      0.38      0.42       133\n",
      "\n",
      "    accuracy                           0.85      2013\n",
      "   macro avg       0.62      0.61      0.61      2013\n",
      "weighted avg       0.85      0.85      0.85      2013\n",
      "\n",
      "Accuracy:  0.8524590163934426\n",
      "Precision: 0.6182141325546014\n",
      "Recall: 0.6059360086107652\n",
      "F1: 0.6108591334847555\n",
      "ROC AUC Score:0.7631887435433408\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "MultinomialNB\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__alpha': 0.9, 'clf_cv__fit_prior': True}\n",
      "Training ROC AUC score: 0.8182301014121067 (0.009251353199771765)\n",
      "Confusion Matrix: \n",
      "[[1345  213   84]\n",
      " [  66  127   45]\n",
      " [   8   58   67]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88      1642\n",
      "           1       0.32      0.53      0.40       238\n",
      "           2       0.34      0.50      0.41       133\n",
      "\n",
      "    accuracy                           0.76      2013\n",
      "   macro avg       0.54      0.62      0.56      2013\n",
      "weighted avg       0.83      0.76      0.79      2013\n",
      "\n",
      "Accuracy:  0.7645305514157973\n",
      "Precision: 0.5362609370314007\n",
      "Recall: 0.6188319548602825\n",
      "F1: 0.5618212268376316\n",
      "ROC AUC Score:0.8312933927229538\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "XGBoost\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__colsample_bytree': 0.8,\n",
      " 'clf_cv__learning_rate': 0.3,\n",
      " 'clf_cv__max_depth': 3,\n",
      " 'clf_cv__min_child_weight': 1,\n",
      " 'clf_cv__n_estimators': 300,\n",
      " 'clf_cv__subsample': 1,\n",
      " 'clf_cv__tree_method': 'gpu_hist'}\n",
      "Training ROC AUC score: 0.9087429082727249 (0.007509481347334376)\n",
      "Confusion Matrix: \n",
      "[[1599   38    5]\n",
      " [ 104  100   34]\n",
      " [  17   41   75]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1642\n",
      "           1       0.56      0.42      0.48       238\n",
      "           2       0.66      0.56      0.61       133\n",
      "\n",
      "    accuracy                           0.88      2013\n",
      "   macro avg       0.72      0.65      0.68      2013\n",
      "weighted avg       0.87      0.88      0.87      2013\n",
      "\n",
      "Accuracy:  0.8812717337307501\n",
      "Precision: 0.7154017058366327\n",
      "Recall: 0.652630088512102\n",
      "F1: 0.6793744228474238\n",
      "ROC AUC Score:0.9132860279675379\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Bigram features\n",
      "\n",
      "Shape before feature selection: (8052, 3000)\n",
      "Shape after feature selection: (8052, 915)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Logistic Regression\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 452, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver saga supports only dual=False, got dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.58292105 0.57631389        nan        nan        nan 0.62698979\n",
      "        nan        nan        nan 0.57905102]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.39609864 0.38774672        nan        nan        nan 0.35893497\n",
      "        nan        nan        nan 0.38478967]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__C': 10,\n",
      " 'clf_cv__dual': False,\n",
      " 'clf_cv__fit_intercept': True,\n",
      " 'clf_cv__max_iter': 10000,\n",
      " 'clf_cv__penalty': 'l2',\n",
      " 'clf_cv__solver': 'lbfgs'}\n",
      "Training ROC AUC score: 0.5913163857395156 (0.012069426861702549)\n",
      "Confusion Matrix: \n",
      "[[1025  341  276]\n",
      " [ 105   81   52]\n",
      " [  47   41   45]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.73      1642\n",
      "           1       0.17      0.34      0.23       238\n",
      "           2       0.12      0.34      0.18       133\n",
      "\n",
      "    accuracy                           0.57      2013\n",
      "   macro avg       0.39      0.43      0.38      2013\n",
      "weighted avg       0.74      0.57      0.63      2013\n",
      "\n",
      "Accuracy:  0.5717834078489816\n",
      "Precision: 0.3888158499346038\n",
      "Recall: 0.43430691078918904\n",
      "F1: 0.3787240911100311\n",
      "ROC AUC Score:0.6252891508318585\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Random Forest\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__bootstrap': True,\n",
      " 'clf_cv__max_depth': None,\n",
      " 'clf_cv__max_features': 'auto',\n",
      " 'clf_cv__min_samples_leaf': 1,\n",
      " 'clf_cv__min_samples_split': 2,\n",
      " 'clf_cv__n_estimators': 1400}\n",
      "Training ROC AUC score: 0.6395027278950747 (0.017718607453686152)\n",
      "Confusion Matrix: \n",
      "[[1635    3    4]\n",
      " [ 234    0    4]\n",
      " [ 126    1    6]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1642\n",
      "           1       0.00      0.00      0.00       238\n",
      "           2       0.43      0.05      0.08       133\n",
      "\n",
      "    accuracy                           0.82      2013\n",
      "   macro avg       0.42      0.35      0.33      2013\n",
      "weighted avg       0.70      0.82      0.74      2013\n",
      "\n",
      "Accuracy:  0.8152011922503726\n",
      "Precision: 0.4160401002506266\n",
      "Recall: 0.34694989605560794\n",
      "F1: 0.3269084372819791\n",
      "ROC AUC Score:0.6085670647867047\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Decision Tree\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__criterion': 'entropy',\n",
      " 'clf_cv__max_depth': 19,\n",
      " 'clf_cv__min_samples_leaf': 1,\n",
      " 'clf_cv__min_samples_split': 9,\n",
      " 'clf_cv__splitter': 'best'}\n",
      "Training ROC AUC score: 0.5376642349385106 (0.019280320621066306)\n",
      "Confusion Matrix: \n",
      "[[1602   30   10]\n",
      " [ 215   15    8]\n",
      " [ 115    7   11]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      1642\n",
      "           1       0.29      0.06      0.10       238\n",
      "           2       0.38      0.08      0.14       133\n",
      "\n",
      "    accuracy                           0.81      2013\n",
      "   macro avg       0.50      0.37      0.38      2013\n",
      "weighted avg       0.74      0.81      0.75      2013\n",
      "\n",
      "Accuracy:  0.8087431693989071\n",
      "Precision: 0.4989881432909919\n",
      "Recall: 0.37379048035651213\n",
      "F1: 0.378575094443424\n",
      "ROC AUC Score:0.5468942023224952\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "MultinomialNB\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__alpha': 1.1, 'clf_cv__fit_prior': True}\n",
      "Training ROC AUC score: 0.6013861259858471 (0.01247759942571946)\n",
      "Confusion Matrix: \n",
      "[[1087  360  195]\n",
      " [ 108   79   51]\n",
      " [  49   41   43]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.66      0.75      1642\n",
      "           1       0.16      0.33      0.22       238\n",
      "           2       0.15      0.32      0.20       133\n",
      "\n",
      "    accuracy                           0.60      2013\n",
      "   macro avg       0.40      0.44      0.39      2013\n",
      "weighted avg       0.74      0.60      0.65      2013\n",
      "\n",
      "Accuracy:  0.6005961251862891\n",
      "Precision: 0.39572215762920765\n",
      "Recall: 0.4390795359107807\n",
      "F1: 0.3923796442641576\n",
      "ROC AUC Score:0.6478856776677736\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "XGBoost\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__colsample_bytree': 0.9,\n",
      " 'clf_cv__learning_rate': 0.3,\n",
      " 'clf_cv__max_depth': 9,\n",
      " 'clf_cv__min_child_weight': 1,\n",
      " 'clf_cv__n_estimators': 300,\n",
      " 'clf_cv__subsample': 1,\n",
      " 'clf_cv__tree_method': 'gpu_hist'}\n",
      "Training ROC AUC score: 0.6257442268706818 (0.017098073376946823)\n",
      "Confusion Matrix: \n",
      "[[1596   42    4]\n",
      " [ 200   29    9]\n",
      " [  90   29   14]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90      1642\n",
      "           1       0.29      0.12      0.17       238\n",
      "           2       0.52      0.11      0.17       133\n",
      "\n",
      "    accuracy                           0.81      2013\n",
      "   macro avg       0.55      0.40      0.42      2013\n",
      "weighted avg       0.76      0.81      0.77      2013\n",
      "\n",
      "Accuracy:  0.8142076502732241\n",
      "Precision: 0.5515846457981488\n",
      "Recall: 0.3996990936896587\n",
      "F1: 0.41711984596599977\n",
      "ROC AUC Score:0.668377580874885\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Ngram features\n",
      "\n",
      "Shape before feature selection: (8052, 3000)\n",
      "Shape after feature selection: (8052, 1065)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Logistic Regression\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 452, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver saga supports only dual=False, got dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.48752153 0.48921343        nan        nan        nan 0.50117769\n",
      "        nan        nan        nan 0.49098323]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.33791608 0.32948046        nan        nan        nan 0.34551331\n",
      "        nan        nan        nan 0.3363545 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__C': 10,\n",
      " 'clf_cv__dual': False,\n",
      " 'clf_cv__fit_intercept': True,\n",
      " 'clf_cv__max_iter': 10000,\n",
      " 'clf_cv__penalty': 'l2',\n",
      " 'clf_cv__solver': 'lbfgs'}\n",
      "Training ROC AUC score: 0.5001262216043725 (0.017488896814259483)\n",
      "Confusion Matrix: \n",
      "[[659 343 640]\n",
      " [ 90  62  86]\n",
      " [ 29  35  69]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.40      0.54      1642\n",
      "           1       0.14      0.26      0.18       238\n",
      "           2       0.09      0.52      0.15       133\n",
      "\n",
      "    accuracy                           0.39      2013\n",
      "   macro avg       0.36      0.39      0.29      2013\n",
      "weighted avg       0.71      0.39      0.48      2013\n",
      "\n",
      "Accuracy:  0.39244908097367115\n",
      "Precision: 0.35824841517958844\n",
      "Recall: 0.3935470078793746\n",
      "F1: 0.29207528372750163\n",
      "ROC AUC Score:0.5579097051938696\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Random Forest\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__bootstrap': True,\n",
      " 'clf_cv__max_depth': 50,\n",
      " 'clf_cv__max_features': 'auto',\n",
      " 'clf_cv__min_samples_leaf': 1,\n",
      " 'clf_cv__min_samples_split': 10,\n",
      " 'clf_cv__n_estimators': 1800}\n",
      "Training ROC AUC score: 0.5380934400888353 (0.011623183066056012)\n",
      "Confusion Matrix: \n",
      "[[671  62 909]\n",
      " [ 84  19 135]\n",
      " [ 30   6  97]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.41      0.55      1642\n",
      "           1       0.22      0.08      0.12       238\n",
      "           2       0.09      0.73      0.15       133\n",
      "\n",
      "    accuracy                           0.39      2013\n",
      "   macro avg       0.39      0.41      0.27      2013\n",
      "weighted avg       0.73      0.39      0.47      2013\n",
      "\n",
      "Accuracy:  0.3909587680079483\n",
      "Precision: 0.38606034034141173\n",
      "Recall: 0.4059344104331905\n",
      "F1: 0.2740484653181104\n",
      "ROC AUC Score:0.56859809250679\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Decision Tree\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__criterion': 'entropy',\n",
      " 'clf_cv__max_depth': 19,\n",
      " 'clf_cv__min_samples_leaf': 1,\n",
      " 'clf_cv__min_samples_split': 9,\n",
      " 'clf_cv__splitter': 'best'}\n",
      "Training ROC AUC score: 0.5159997194933036 (0.004386471495416423)\n",
      "Confusion Matrix: \n",
      "[[ 141    9 1492]\n",
      " [  16    4  218]\n",
      " [   7    3  123]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.09      0.16      1642\n",
      "           1       0.25      0.02      0.03       238\n",
      "           2       0.07      0.92      0.13       133\n",
      "\n",
      "    accuracy                           0.13      2013\n",
      "   macro avg       0.39      0.34      0.10      2013\n",
      "weighted avg       0.74      0.13      0.14      2013\n",
      "\n",
      "Accuracy:  0.13313462493790362\n",
      "Precision: 0.3922864024057589\n",
      "Recall: 0.3424965473079417\n",
      "F1: 0.104256468047955\n",
      "ROC AUC Score:0.5154051790516517\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "MultinomialNB\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__alpha': 0.9, 'clf_cv__fit_prior': True}\n",
      "Training ROC AUC score: 0.5040503665808951 (0.017073211105844817)\n",
      "Confusion Matrix: \n",
      "[[1061  329  252]\n",
      " [ 129   64   45]\n",
      " [  74   31   28]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73      1642\n",
      "           1       0.15      0.27      0.19       238\n",
      "           2       0.09      0.21      0.12       133\n",
      "\n",
      "    accuracy                           0.57      2013\n",
      "   macro avg       0.36      0.38      0.35      2013\n",
      "weighted avg       0.71      0.57      0.63      2013\n",
      "\n",
      "Accuracy:  0.5727769498261301\n",
      "Precision: 0.35883199218582545\n",
      "Recall: 0.3751990314684756\n",
      "F1: 0.34861252278816224\n",
      "ROC AUC Score:0.5704772048995278\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "XGBoost\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__colsample_bytree': 0.8,\n",
      " 'clf_cv__learning_rate': 0.3,\n",
      " 'clf_cv__max_depth': 5,\n",
      " 'clf_cv__min_child_weight': 1,\n",
      " 'clf_cv__n_estimators': 300,\n",
      " 'clf_cv__subsample': 1,\n",
      " 'clf_cv__tree_method': 'gpu_hist'}\n",
      "Training ROC AUC score: 0.5359788971605318 (0.01432245570805022)\n",
      "Confusion Matrix: \n",
      "[[1505   82   55]\n",
      " [ 195   31   12]\n",
      " [ 107   14   12]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1642\n",
      "           1       0.24      0.13      0.17       238\n",
      "           2       0.15      0.09      0.11       133\n",
      "\n",
      "    accuracy                           0.77      2013\n",
      "   macro avg       0.41      0.38      0.39      2013\n",
      "weighted avg       0.72      0.77      0.74      2013\n",
      "\n",
      "Accuracy:  0.7690014903129657\n",
      "Precision: 0.4096217953912024\n",
      "Recall: 0.3790142763945761\n",
      "F1: 0.38526243011841643\n",
      "ROC AUC Score:0.5931635157805815\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "TFIDF features\n",
      "\n",
      "Shape before feature selection: (8052, 3000)\n",
      "Shape after feature selection: (8052, 529)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Logistic Regression\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 452, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver saga supports only dual=False, got dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.77332642 0.74649066        nan        nan        nan 0.78430572\n",
      "        nan        nan        nan 0.75853291]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.51274649 0.51809549        nan        nan        nan 0.53851854\n",
      "        nan        nan        nan 0.50585576]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__C': 10,\n",
      " 'clf_cv__dual': False,\n",
      " 'clf_cv__fit_intercept': True,\n",
      " 'clf_cv__max_iter': 10000,\n",
      " 'clf_cv__penalty': 'l2',\n",
      " 'clf_cv__solver': 'lbfgs'}\n",
      "Training ROC AUC score: 0.8734349037239646 (0.010514900614072684)\n",
      "Confusion Matrix: \n",
      "[[1502  106   34]\n",
      " [  60  127   51]\n",
      " [   7   51   75]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      1642\n",
      "           1       0.45      0.53      0.49       238\n",
      "           2       0.47      0.56      0.51       133\n",
      "\n",
      "    accuracy                           0.85      2013\n",
      "   macro avg       0.62      0.67      0.64      2013\n",
      "weighted avg       0.86      0.85      0.85      2013\n",
      "\n",
      "Accuracy:  0.8464977645305514\n",
      "Precision: 0.6244102468005398\n",
      "Recall: 0.6707537813509915\n",
      "F1: 0.6446898441105494\n",
      "ROC AUC Score:0.8924118883582515\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Random Forest\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__bootstrap': True,\n",
      " 'clf_cv__max_depth': 60,\n",
      " 'clf_cv__max_features': 'auto',\n",
      " 'clf_cv__min_samples_leaf': 1,\n",
      " 'clf_cv__min_samples_split': 10,\n",
      " 'clf_cv__n_estimators': 600}\n",
      "Training ROC AUC score: 0.8847610524557752 (0.010510445985247295)\n",
      "Confusion Matrix: \n",
      "[[1585   46   11]\n",
      " [ 139   53   46]\n",
      " [  34   20   79]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      1642\n",
      "           1       0.45      0.22      0.30       238\n",
      "           2       0.58      0.59      0.59       133\n",
      "\n",
      "    accuracy                           0.85      2013\n",
      "   macro avg       0.64      0.59      0.61      2013\n",
      "weighted avg       0.83      0.85      0.83      2013\n",
      "\n",
      "Accuracy:  0.8529557873820169\n",
      "Precision: 0.6426177410668478\n",
      "Recall: 0.5939867581111553\n",
      "F1: 0.6055441011596708\n",
      "ROC AUC Score:0.883250720462644\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Decision Tree\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__criterion': 'gini',\n",
      " 'clf_cv__max_depth': 29,\n",
      " 'clf_cv__min_samples_leaf': 9,\n",
      " 'clf_cv__min_samples_split': 7,\n",
      " 'clf_cv__splitter': 'best'}\n",
      "Training ROC AUC score: 0.7577846261644119 (0.019423094652426334)\n",
      "Confusion Matrix: \n",
      "[[1541   78   23]\n",
      " [  78   94   66]\n",
      " [  11   52   70]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1642\n",
      "           1       0.42      0.39      0.41       238\n",
      "           2       0.44      0.53      0.48       133\n",
      "\n",
      "    accuracy                           0.85      2013\n",
      "   macro avg       0.60      0.62      0.61      2013\n",
      "weighted avg       0.85      0.85      0.85      2013\n",
      "\n",
      "Accuracy:  0.8469945355191257\n",
      "Precision: 0.6017644008253454\n",
      "Recall: 0.6199211398130635\n",
      "F1: 0.6094366673544086\n",
      "ROC AUC Score:0.7823329355077983\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "MultinomialNB\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__alpha': 0.9, 'clf_cv__fit_prior': True}\n",
      "Training ROC AUC score: 0.8158913377646437 (0.010971529109405945)\n",
      "Confusion Matrix: \n",
      "[[1340  217   85]\n",
      " [  65  131   42]\n",
      " [   6   69   58]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88      1642\n",
      "           1       0.31      0.55      0.40       238\n",
      "           2       0.31      0.44      0.36       133\n",
      "\n",
      "    accuracy                           0.76      2013\n",
      "   macro avg       0.53      0.60      0.55      2013\n",
      "weighted avg       0.83      0.76      0.79      2013\n",
      "\n",
      "Accuracy:  0.7595628415300546\n",
      "Precision: 0.5257810906062822\n",
      "Recall: 0.6008627824487062\n",
      "F1: 0.5475349880963907\n",
      "ROC AUC Score:0.8437169837473805\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "XGBoost\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__colsample_bytree': 0.9,\n",
      " 'clf_cv__learning_rate': 0.3,\n",
      " 'clf_cv__max_depth': 9,\n",
      " 'clf_cv__min_child_weight': 1,\n",
      " 'clf_cv__n_estimators': 300,\n",
      " 'clf_cv__subsample': 1,\n",
      " 'clf_cv__tree_method': 'gpu_hist'}\n",
      "Training ROC AUC score: 0.9026435698091467 (0.007302184099483776)\n",
      "Confusion Matrix: \n",
      "[[1594   43    5]\n",
      " [  99   93   46]\n",
      " [  17   45   71]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1642\n",
      "           1       0.51      0.39      0.44       238\n",
      "           2       0.58      0.53      0.56       133\n",
      "\n",
      "    accuracy                           0.87      2013\n",
      "   macro avg       0.68      0.63      0.65      2013\n",
      "weighted avg       0.86      0.87      0.87      2013\n",
      "\n",
      "Accuracy:  0.8733233979135618\n",
      "Precision: 0.6759810368336484\n",
      "Recall: 0.6317860819563418\n",
      "F1: 0.6506169373079383\n",
      "ROC AUC Score:0.9097335236210403\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Hateful features\n",
      "\n",
      "Shape before feature selection: (8052, 37)\n",
      "Shape after feature selection: (8052, 20)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Logistic Regression\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 452, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver saga supports only dual=False, got dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.67182728 0.67024986        nan        nan        nan 0.66414335\n",
      "        nan        nan        nan 0.66272444]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.33363348 0.32045547        nan        nan        nan 0.29625487\n",
      "        nan        nan        nan 0.29625487]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__C': 100,\n",
      " 'clf_cv__dual': False,\n",
      " 'clf_cv__fit_intercept': False,\n",
      " 'clf_cv__max_iter': 10000,\n",
      " 'clf_cv__penalty': 'l1',\n",
      " 'clf_cv__solver': 'saga'}\n",
      "Training ROC AUC score: 0.6656813759601732 (0.013944080529916636)\n",
      "Confusion Matrix: \n",
      "[[983 240 419]\n",
      " [ 76  55 107]\n",
      " [ 41  21  71]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.60      0.72      1642\n",
      "           1       0.17      0.23      0.20       238\n",
      "           2       0.12      0.53      0.19       133\n",
      "\n",
      "    accuracy                           0.55      2013\n",
      "   macro avg       0.40      0.45      0.37      2013\n",
      "weighted avg       0.76      0.55      0.62      2013\n",
      "\n",
      "Accuracy:  0.5509190263288624\n",
      "Precision: 0.39553832324902866\n",
      "Recall: 0.4545290646549023\n",
      "F1: 0.37002379962056287\n",
      "ROC AUC Score:0.6597016282965323\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Random Forest\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__bootstrap': False,\n",
      " 'clf_cv__max_depth': 110,\n",
      " 'clf_cv__max_features': 'auto',\n",
      " 'clf_cv__min_samples_leaf': 4,\n",
      " 'clf_cv__min_samples_split': 2,\n",
      " 'clf_cv__n_estimators': 1400}\n",
      "Training ROC AUC score: 0.6481803065729589 (0.01183618719981465)\n",
      "Confusion Matrix: \n",
      "[[1457  112   73]\n",
      " [ 180   40   18]\n",
      " [ 101   10   22]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1642\n",
      "           1       0.25      0.17      0.20       238\n",
      "           2       0.19      0.17      0.18       133\n",
      "\n",
      "    accuracy                           0.75      2013\n",
      "   macro avg       0.43      0.41      0.41      2013\n",
      "weighted avg       0.73      0.75      0.74      2013\n",
      "\n",
      "Accuracy:  0.754595131644312\n",
      "Precision: 0.4266412512246001\n",
      "Recall: 0.4069377606802706\n",
      "F1: 0.41366398871089305\n",
      "ROC AUC Score:0.6482432810738413\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Decision Tree\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__criterion': 'gini',\n",
      " 'clf_cv__max_depth': 2,\n",
      " 'clf_cv__min_samples_leaf': 5,\n",
      " 'clf_cv__min_samples_split': 7,\n",
      " 'clf_cv__splitter': 'best'}\n",
      "Training ROC AUC score: 0.5931008801876134 (0.012207351282145208)\n",
      "Confusion Matrix: \n",
      "[[372 424 846]\n",
      " [ 28  70 140]\n",
      " [ 16  26  91]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.23      0.36      1642\n",
      "           1       0.13      0.29      0.18       238\n",
      "           2       0.08      0.68      0.15       133\n",
      "\n",
      "    accuracy                           0.26      2013\n",
      "   macro avg       0.37      0.40      0.23      2013\n",
      "weighted avg       0.75      0.26      0.33      2013\n",
      "\n",
      "Accuracy:  0.2647789369100845\n",
      "Precision: 0.37111337285431995\n",
      "Recall: 0.40162705251342157\n",
      "F1: 0.23220860934892096\n",
      "ROC AUC Score:0.5691877958949988\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "MultinomialNB\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__alpha': 0.5, 'clf_cv__fit_prior': False}\n",
      "Training ROC AUC score: 0.6137594365960518 (0.014760814607863628)\n",
      "Confusion Matrix: \n",
      "[[643 397 602]\n",
      " [ 66  79  93]\n",
      " [ 30  29  74]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.39      0.54      1642\n",
      "           1       0.16      0.33      0.21       238\n",
      "           2       0.10      0.56      0.16       133\n",
      "\n",
      "    accuracy                           0.40      2013\n",
      "   macro avg       0.37      0.43      0.31      2013\n",
      "weighted avg       0.73      0.40      0.48      2013\n",
      "\n",
      "Accuracy:  0.39542970690511675\n",
      "Precision: 0.37425307827435333\n",
      "Recall: 0.4266397885521283\n",
      "F1: 0.3056134778740743\n",
      "ROC AUC Score:0.601154092209406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "XGBoost\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__colsample_bytree': 0.9,\n",
      " 'clf_cv__learning_rate': 0.3,\n",
      " 'clf_cv__max_depth': 9,\n",
      " 'clf_cv__min_child_weight': 1,\n",
      " 'clf_cv__n_estimators': 300,\n",
      " 'clf_cv__subsample': 1,\n",
      " 'clf_cv__tree_method': 'gpu_hist'}\n",
      "Training ROC AUC score: 0.6215005243185492 (0.011513456735615596)\n",
      "Confusion Matrix: \n",
      "[[1563   50   29]\n",
      " [ 208   20   10]\n",
      " [ 123    6    4]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88      1642\n",
      "           1       0.26      0.08      0.13       238\n",
      "           2       0.09      0.03      0.05       133\n",
      "\n",
      "    accuracy                           0.79      2013\n",
      "   macro avg       0.39      0.36      0.35      2013\n",
      "weighted avg       0.71      0.79      0.74      2013\n",
      "\n",
      "Accuracy:  0.7883755588673621\n",
      "Precision: 0.39380624764927963\n",
      "Recall: 0.3553322476500056\n",
      "F1: 0.35229761808068294\n",
      "ROC AUC Score:0.6348074114516525\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Word2Vec features\n",
      "\n",
      "Shape before feature selection: (8052, 300)\n",
      "Shape after feature selection: (8052, 86)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Logistic Regression\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 452, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver saga supports only dual=False, got dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1528, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.77220876 0.76234011        nan        nan        nan 0.79320402\n",
      "        nan        nan        nan 0.7967001 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hind\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.4634706  0.45750663        nan        nan        nan 0.48521806\n",
      "        nan        nan        nan 0.46445962]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Best parameters:\n",
      "\n",
      "{'clf_cv__C': 10,\n",
      " 'clf_cv__dual': False,\n",
      " 'clf_cv__fit_intercept': False,\n",
      " 'clf_cv__max_iter': 10000,\n",
      " 'clf_cv__penalty': 'l2',\n",
      " 'clf_cv__solver': 'newton-cg'}\n",
      "Training ROC AUC score: 0.7992874897003693 (0.007855075296594174)\n",
      "Confusion Matrix: \n",
      "[[1234  292  116]\n",
      " [  66  103   69]\n",
      " [  19   24   90]]\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83      1642\n",
      "           1       0.25      0.43      0.31       238\n",
      "           2       0.33      0.68      0.44       133\n",
      "\n",
      "    accuracy                           0.71      2013\n",
      "   macro avg       0.50      0.62      0.53      2013\n",
      "weighted avg       0.81      0.71      0.75      2013\n",
      "\n",
      "Accuracy:  0.7088922006954794\n",
      "Precision: 0.5028844522092643\n",
      "Recall: 0.6203291240209142\n",
      "F1: 0.5294083629760075\n",
      "ROC AUC Score:0.806477277387498\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Random Forest\n",
      "____________________________________________________________________________________________________\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136ea72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
